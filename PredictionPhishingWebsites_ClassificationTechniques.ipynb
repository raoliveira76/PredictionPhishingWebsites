{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection and Prediction of Phishing Websites using Classification Mining Techniques\n",
    "\n",
    "**Mofleh Al-diabat**\\\n",
    "Department of Computer Science - Al Albayt University\\\n",
    "International Journal of Computer Applications (0975 – 8887) - Volume 147 – No.5, August 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*ABSTRACT*\\\n",
    "Phishing is serious web security problem that involves mimicking legitimate websites to deceive online users in order to steal their sensitive information. Phishing can be seen as a typical classification problem in data mining where the classifier is constructed from large number of website’s features. There are high demands on identifying the best set of features that when mined the predictive accuracy of the classifiers is enhanced. This paper investigates features selection aiming to determine the effective set of features in terms of classification performance. We compare two known features selection method in order to determine the least set of features of phishing detection using data mining. Experimental tests on large number of features data set have been done using Information Gain and Correlation Features set methods. Further, two data mining algorithms namely C4.5 and IREP have been trained on different sets of selected features to show the pros and cons of the feature selection process. We have been able to identify new knowledge in the forms of rules that show vital correlations among significant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SFH</th>\n",
       "      <th>popUpWindow</th>\n",
       "      <th>SSLFinal_State</th>\n",
       "      <th>Request_URL</th>\n",
       "      <th>URL_of_Anchor</th>\n",
       "      <th>Web_Traffic</th>\n",
       "      <th>URL_Length</th>\n",
       "      <th>Age_of_Domain</th>\n",
       "      <th>Having_IP_Address</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SFH  popUpWindow  SSLFinal_State  Request_URL  URL_of_Anchor  Web_Traffic  \\\n",
       "0    1           -1               1           -1             -1            1   \n",
       "1   -1           -1              -1           -1             -1            0   \n",
       "2    1           -1               0            0             -1            0   \n",
       "3    1            0               1           -1             -1            0   \n",
       "4   -1           -1               1           -1              0            0   \n",
       "\n",
       "   URL_Length  Age_of_Domain  Having_IP_Address  Result  \n",
       "0           1              1                  0       0  \n",
       "1           1              1                  1       1  \n",
       "2          -1              1                  0       1  \n",
       "3           1              1                  0       0  \n",
       "4          -1              1                  0       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phishing_data = pd.read_csv('phishing_data.csv')\n",
    "phishing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = phishing_data.drop('Result', axis=1)\n",
    "y = phishing_data['Result']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "model score: 0.844\n",
      "\n",
      " -----------------------------------------------------------------------------------\n",
      "KNeighborsClassifier(n_neighbors=3)\n",
      "model score: 0.882\n",
      "\n",
      " -----------------------------------------------------------------------------------\n",
      "SVC(C=0.025, kernel='linear')\n",
      "model score: 0.808\n",
      "\n",
      " -----------------------------------------------------------------------------------\n",
      "SVC(C=1, gamma=2)\n",
      "model score: 0.867\n",
      "\n",
      " -----------------------------------------------------------------------------------\n",
      "GaussianProcessClassifier(kernel=1**2 * RBF(length_scale=1))\n",
      "model score: 0.844\n",
      "\n",
      " -----------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier(max_depth=5)\n",
      "model score: 0.838\n",
      "\n",
      " -----------------------------------------------------------------------------------\n",
      "RandomForestClassifier(max_depth=5, max_features=1, n_estimators=10)\n",
      "model score: 0.832\n",
      "\n",
      " -----------------------------------------------------------------------------------\n",
      "MLPClassifier(alpha=0.001, learning_rate='adaptive', max_iter=1000,\n",
      "              solver='lbfgs')\n",
      "model score: 0.909\n",
      "\n",
      " -----------------------------------------------------------------------------------\n",
      "AdaBoostClassifier()\n",
      "model score: 0.838\n",
      "\n",
      " -----------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Anaconda3\\envs\\env37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:55:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=12, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "model score: 0.900\n",
      "\n",
      " -----------------------------------------------------------------------------------\n",
      "GaussianNB()\n",
      "model score: 0.823\n",
      "\n",
      " -----------------------------------------------------------------------------------\n",
      "QuadraticDiscriminantAnalysis()\n",
      "model score: 0.847\n",
      "\n",
      " -----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "names = [\"Logististic Regression\", \"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\", \"XGBoost\",\"Naive Bayes\", \"QDA\"]\n",
    "scores = []\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=0.001, solver='lbfgs', learning_rate='adaptive', max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    XGBClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    pipe = Pipeline(steps=[('classifier', classifier)])\n",
    "    pipe.fit(X_train, y_train)   \n",
    "    \n",
    "    scores.append(pipe.score(X_test, y_test))\n",
    "    \n",
    "    print(classifier)    \n",
    "    print(\"model score: %.3f\" % pipe.score(X_test, y_test))\n",
    "    print(\"\\n -----------------------------------------------------------------------------------\")\n",
    "    \n",
    "#end of pipeline\n",
    "scores_df = pd.DataFrame(zip(names,scores), columns=['Classifier', 'Accuracy Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Classifier  Accuracy Score\n",
      "7               Neural Net        0.908555\n",
      "9                  XGBoost        0.899705\n",
      "1        Nearest Neighbors        0.882006\n",
      "3                  RBF SVM        0.867257\n",
      "11                     QDA        0.846608\n",
      "0   Logististic Regression        0.843658\n",
      "4         Gaussian Process        0.843658\n",
      "5            Decision Tree        0.837758\n",
      "8                 AdaBoost        0.837758\n",
      "6            Random Forest        0.831858\n",
      "10             Naive Bayes        0.823009\n",
      "2               Linear SVM        0.808260\n"
     ]
    }
   ],
   "source": [
    "print(scores_df.sort_values(by='Accuracy Score', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
